GPU!!!!!!!!!
/mnt/ncshare/ozkilim/TensorRush/soundbay/soundbay/models.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(weight_path)
Error executing job with overrides: ['model.model.weight_path=/mnt/ncshare/ozkilim/TensorRush/FM_pipeline/dino/W_AST_state_dict.pt']
Traceback (most recent call last):
  File "/mnt/ncshare/ozkilim/TensorRush/soundbay/soundbay/train.py", line 259, in main
    modeling(
  File "/mnt/ncshare/ozkilim/TensorRush/soundbay/soundbay/train.py", line 106, in modeling
    model = models_dict[model_args.pop('_target_')](**model_args)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ncshare/ozkilim/TensorRush/soundbay/soundbay/models.py", line 57, in __init__
    self.model.load_state_dict(state_dict)
  File "/home/ozkilim/anaconda3/envs/whaleViT/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ASTModel:
	Missing key(s) in state_dict: "embeddings.cls_token", "embeddings.distillation_token", "embeddings.position_embeddings", "embeddings.patch_embeddings.projection.weight", "embeddings.patch_embeddings.projection.bias", "encoder.layer.0.attention.attention.query.weight", "encoder.layer.0.attention.attention.query.bias", "encoder.layer.0.attention.attention.key.weight", "encoder.layer.0.attention.attention.key.bias", "encoder.layer.0.attention.attention.value.weight", "encoder.layer.0.attention.attention.value.bias", "encoder.layer.0.attention.output.dense.weight", "encoder.layer.0.attention.output.dense.bias", "encoder.layer.0.intermediate.dense.weight", "encoder.layer.0.intermediate.dense.bias", "encoder.layer.0.output.dense.weight", "encoder.layer.0.output.dense.bias", "encoder.layer.0.layernorm_before.weight", "encoder.layer.0.layernorm_before.bias", "encoder.layer.0.layernorm_after.weight", "encoder.layer.0.layernorm_after.bias", "encoder.layer.1.attention.attention.query.weight", "encoder.layer.1.attention.attention.query.bias", "encoder.layer.1.attention.attention.key.weight", "encoder.layer.1.attention.attention.key.bias", "encoder.layer.1.attention.attention.value.weight", "encoder.layer.1.attention.attention.value.bias", "encoder.layer.1.attention.output.dense.weight", "encoder.layer.1.attention.output.dense.bias", "encoder.layer.1.intermediate.dense.weight", "encoder.layer.1.intermediate.dense.bias", "encoder.layer.1.output.dense.weight", "encoder.layer.1.output.dense.bias", "encoder.layer.1.layernorm_before.weight", "encoder.layer.1.layernorm_before.bias", "encoder.layer.1.layernorm_after.weight", "encoder.layer.1.layernorm_after.bias", "encoder.layer.2.attention.attention.query.weight", "encoder.layer.2.attention.attention.query.bias", "encoder.layer.2.attention.attention.key.weight", "encoder.layer.2.attention.attention.key.bias", "encoder.layer.2.attention.attention.value.weight", "encoder.layer.2.attention.attention.value.bias", "encoder.layer.2.attention.output.dense.weight", "encoder.layer.2.attention.output.dense.bias", "encoder.layer.2.intermediate.dense.weight", "encoder.layer.2.intermediate.dense.bias", "encoder.layer.2.output.dense.weight", "encoder.layer.2.output.dense.bias", "encoder.layer.2.layernorm_before.weight", "encoder.layer.2.layernorm_before.bias", "encoder.layer.2.layernorm_after.weight", "encoder.layer.2.layernorm_after.bias", "encoder.layer.3.attention.attention.query.weight", "encoder.layer.3.attention.attention.query.bias", "encoder.layer.3.attention.attention.key.weight", "encoder.layer.3.attention.attention.key.bias", "encoder.layer.3.attention.attention.value.weight", "encoder.layer.3.attention.attention.value.bias", "encoder.layer.3.attention.output.dense.weight", "encoder.layer.3.attention.output.dense.bias", "encoder.layer.3.intermediate.dense.weight", "encoder.layer.3.intermediate.dense.bias", "encoder.layer.3.output.dense.weight", "encoder.layer.3.output.dense.bias", "encoder.layer.3.layernorm_before.weight", "encoder.layer.3.layernorm_before.bias", "encoder.layer.3.layernorm_after.weight", "encoder.layer.3.layernorm_after.bias", "encoder.layer.4.attention.attention.query.weight", "encoder.layer.4.attention.attention.query.bias", "encoder.layer.4.attention.attention.key.weight", "encoder.layer.4.attention.attention.key.bias", "encoder.layer.4.attention.attention.value.weight", "encoder.layer.4.attention.attention.value.bias", "encoder.layer.4.attention.output.dense.weight", "encoder.layer.4.attention.output.dense.bias", "encoder.layer.4.intermediate.dense.weight", "encoder.layer.4.intermediate.dense.bias", "encoder.layer.4.output.dense.weight", "encoder.layer.4.output.dense.bias", "encoder.layer.4.layernorm_before.weight", "encoder.layer.4.layernorm_before.bias", "encoder.layer.4.layernorm_after.weight", "encoder.layer.4.layernorm_after.bias", "encoder.layer.5.attention.attention.query.weight", "encoder.layer.5.attention.attention.query.bias", "encoder.layer.5.attention.attention.key.weight", "encoder.layer.5.attention.attention.key.bias", "encoder.layer.5.attention.attention.v
	Unexpected key(s) in state_dict: "backbone.embeddings.cls_token", "backbone.embeddings.distillation_token", "backbone.embeddings.position_embeddings", "backbone.embeddings.patch_embeddings.projection.weight", "backbone.embeddings.patch_embeddings.projection.bias", "backbone.encoder.layer.0.attention.attention.query.weight", "backbone.encoder.layer.0.attention.attention.query.bias", "backbone.encoder.layer.0.attention.attention.key.weight", "backbone.encoder.layer.0.attention.attention.key.bias", "backbone.encoder.layer.0.attention.attention.value.weight", "backbone.encoder.layer.0.attention.attention.value.bias", "backbone.encoder.layer.0.attention.output.dense.weight", "backbone.encoder.layer.0.attention.output.dense.bias", "backbone.encoder.layer.0.intermediate.dense.weight", "backbone.encoder.layer.0.intermediate.dense.bias", "backbone.encoder.layer.0.output.dense.weight", "backbone.encoder.layer.0.output.dense.bias", "backbone.encoder.layer.0.layernorm_before.weight", "backbone.encoder.layer.0.layernorm_before.bias", "backbone.encoder.layer.0.layernorm_after.weight", "backbone.encoder.layer.0.layernorm_after.bias", "backbone.encoder.layer.1.attention.attention.query.weight", "backbone.encoder.layer.1.attention.attention.query.bias", "backbone.encoder.layer.1.attention.attention.key.weight", "backbone.encoder.layer.1.attention.attention.key.bias", "backbone.encoder.layer.1.attention.attention.value.weight", "backbone.encoder.layer.1.attention.attention.value.bias", "backbone.encoder.layer.1.attention.output.dense.weight", "backbone.encoder.layer.1.attention.output.dense.bias", "backbone.encoder.layer.1.intermediate.dense.weight", "backbone.encoder.layer.1.intermediate.dense.bias", "backbone.encoder.layer.1.output.dense.weight", "backbone.encoder.layer.1.output.dense.bias", "backbone.encoder.layer.1.layernorm_before.weight", "backbone.encoder.layer.1.layernorm_before.bias", "backbone.encoder.layer.1.layernorm_after.weight", "backbone.encoder.layer.1.layernorm_after.bias", "backbone.encoder.layer.2.attention.attention.query.weight", "backbone.encoder.layer.2.attention.attention.query.bias", "backbone.encoder.layer.2.attention.attention.key.weight", "backbone.encoder.layer.2.attention.attention.key.bias", "backbone.encoder.layer.2.attention.attention.value.weight", "backbone.encoder.layer.2.attention.attention.value.bias", "backbone.encoder.layer.2.attention.output.dense.weight", "backbone.encoder.layer.2.attention.output.dense.bias", "backbone.encoder.layer.2.intermediate.dense.weight", "backbone.encoder.layer.2.intermediate.dense.bias", "backbone.encoder.layer.2.output.dense.weight", "backbone.encoder.layer.2.output.dense.bias", "backbone.encoder.layer.2.layernorm_before.weight", "backbone.encoder.layer.2.layernorm_before.bias", "backbone.encoder.layer.2.layernorm_after.weight", "backbone.encoder.layer.2.layernorm_after.bias", "backbone.encoder.layer.3.attention.attention.query.weight", "backbone.encoder.layer.3.attention.attention.query.bias", "backbone.encoder.layer.3.attention.attention.key.weight", "backbone.encoder.layer.3.attention.attention.key.bias", "backbone.encoder.layer.3.attention.attention.value.weight", "backbone.encoder.layer.3.attention.attention.value.bias", "backbone.encoder.layer.3.attention.output.dense.weight", "backbone.encoder.layer.3.attention.output.dense.bias", "backbone.encoder.layer.3.intermediate.dense.weight", "backbone.encoder.layer.3.intermediate.dense.bias", "backbone.encoder.layer.3.output.dense.weight", "backbone.encoder.layer.3.output.dense.bias", "backbone.encoder.layer.3.layernorm_before.weight", "backbone.encoder.layer.3.layernorm_before.bias", "backbone.encoder.layer.3.layernorm_after.weight", "backbone.encoder.layer.3.layernorm_after.bias", "backbone.encoder.layer.4.attention.attention.query.weight", "backbone.encoder.layer.4.attention.attention.query.bias", "backbone.encoder.layer.4.attention.attention.key.weight", "backbone.encoder.layer.4.attention.attention.key.bias", "backbone.encoder.layer.4.attention.attention.value.weight", "backbone.encoder.layer.4.attention.attention

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
