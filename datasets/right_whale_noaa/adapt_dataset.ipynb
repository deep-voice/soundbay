{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48836b17-90bd-4aaf-a3eb-9fe74abd485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from soundbay.utils.metadata_processing import (\n",
    "    bg_from_non_overlap_calls,\n",
    "    correct_call_times_with_duration,\n",
    "    non_overlap_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c6ea5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d895fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "deepvoice_directory = os.path.dirname(\n",
    "    os.path.dirname(os.path.dirname(current_directory))\n",
    ")\n",
    "\n",
    "nefsc_folder_path = os.path.join(\n",
    "    deepvoice_directory, \"datasets\", \"nefsc_sbnms_200903_nopp6_ch10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78b9b3-727e-4ad6-9c36-c5d57050d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{nefsc_folder_path}/detections/NEFSC_SBNMS_200903_NOPP6_CH10_allbaleen_detection_log.csv\"\n",
    "original_metadata = pd.read_csv(data_path)\n",
    "audio_files_path = f\"{nefsc_folder_path}/source-audio/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7ae48",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a25b6-83e9-41ea-b278-702b1c8fa5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_DELTA = 15 * 60  # 15 minutes files\n",
    "\n",
    "\n",
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\"\"\"\n",
    "    h, m, s = time_str.split(\":\")\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "\n",
    "def filetime_from_time(time_str):\n",
    "    sec_time = get_sec(time_str)\n",
    "    filetime_sec = math.floor(sec_time / FILES_DELTA) * FILES_DELTA\n",
    "    filetime_str = time.strftime(\"%H%M%S\", time.gmtime(filetime_sec))\n",
    "    return filetime_str\n",
    "\n",
    "\n",
    "def get_time_and_date(iso_input):\n",
    "    date, time_str = iso_input.split(\"T\")\n",
    "    time_str = time_str.split(\"-\")[0]\n",
    "    return date, time_str\n",
    "\n",
    "\n",
    "def iso_to_file_name(iso_input):\n",
    "    date, time_str = get_time_and_date(iso_input)\n",
    "    filename_time = filetime_from_time(time_str)\n",
    "    filename_date = date.replace(\"-\", \"\")\n",
    "    return f\"NOPP6_EST_{filename_date}_{filename_time}_CH10\"\n",
    "\n",
    "\n",
    "def get_time_in_file(iso_input, type=\"start\"):\n",
    "    date, time_str = get_time_and_date(iso_input)\n",
    "    time_int = get_sec(time_str)\n",
    "    time_in_file = time_int - (time_int // FILES_DELTA) * FILES_DELTA\n",
    "    if type == \"end\" and time_in_file == 0:\n",
    "        time_in_file = FILES_DELTA\n",
    "    return time_in_file\n",
    "\n",
    "\n",
    "def get_previous_filename(filename):\n",
    "    file_parts = filename.split(\"_\")\n",
    "    time_part = file_parts[-2]\n",
    "    h, m, s = re.findall(\"..\", time_part)\n",
    "    time_sec = int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    new_time = time_sec - FILES_DELTA\n",
    "    assert new_time % FILES_DELTA == 0, \"whyyyy\"\n",
    "    new_time_part = time.strftime(\"%H%M%S\", time.gmtime(new_time))\n",
    "    file_parts[-2] = new_time_part\n",
    "    return \"_\".join(file_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlaps_with_buffer(df, buffer_seconds):\n",
    "    # Convert start and end times to datetime format\n",
    "    df[\"Start_DateTime_ISO8601\"] = pd.to_datetime(df[\"Start_DateTime_ISO8601\"])\n",
    "    df[\"End_DateTime_ISO8601\"] = pd.to_datetime(df[\"End_DateTime_ISO8601\"])\n",
    "\n",
    "    # Sort the data by start time for easier analysis\n",
    "    df = df.sort_values(by=[\"Start_DateTime_ISO8601\", \"filename\"]).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    # Efficient overlap detection handling multi-sample overlaps\n",
    "    overlaps = []\n",
    "    active_intervals = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        current_species = df.loc[i, \"Species\"]\n",
    "        current_start = df.loc[i, \"Start_DateTime_ISO8601\"] - timedelta(\n",
    "            seconds=buffer_seconds\n",
    "        )  # Extend start time by buffer\n",
    "        current_end = df.loc[i, \"End_DateTime_ISO8601\"] + timedelta(\n",
    "            seconds=buffer_seconds\n",
    "        )  # Extend end time by buffer\n",
    "        current_filename = df.loc[i, \"filename\"]\n",
    "        current_unique_id = df.loc[i, \"unique_id\"]\n",
    "\n",
    "        # Remove intervals that have ended\n",
    "        active_intervals = [\n",
    "            interval\n",
    "            for interval in active_intervals\n",
    "            if interval[\"end\"] > current_start\n",
    "        ]\n",
    "\n",
    "        # Check for overlaps with all active intervals\n",
    "        for interval in active_intervals:\n",
    "            if interval[\"species\"] != current_species:\n",
    "                overlap_start = max(interval[\"start\"], current_start)\n",
    "                overlap_end = min(interval[\"end\"], current_end)\n",
    "\n",
    "                # Ensure there is an actual overlap\n",
    "                if overlap_start < overlap_end:\n",
    "                    overlaps.append(\n",
    "                        {\n",
    "                            \"Current Species\": interval[\"species\"],\n",
    "                            \"Next Species\": current_species,\n",
    "                            \"Overlap Start\": overlap_start,\n",
    "                            \"Overlap End\": overlap_end,\n",
    "                            \"Overlaps Duration\": (\n",
    "                                overlap_end - overlap_start\n",
    "                            ).total_seconds(),\n",
    "                            \"File 1\": interval[\"filename\"],\n",
    "                            \"File 1 Unique ID\": interval[\"unique_id\"],\n",
    "                            \"File 2\": current_filename,\n",
    "                            \"File 2 Unique ID\": current_unique_id,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Add the current interval to the active list\n",
    "        active_intervals.append(\n",
    "            {\n",
    "                \"species\": current_species,\n",
    "                \"start\": current_start,\n",
    "                \"end\": current_end,\n",
    "                \"filename\": current_filename,\n",
    "                \"unique_id\": current_unique_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Convert overlaps to a DataFrame for better visualization\n",
    "    overlaps_df = pd.DataFrame(overlaps)\n",
    "\n",
    "    # Remove duplicates based on overlap times and species, ignoring different filenames\n",
    "    overlaps_df = overlaps_df.drop_duplicates(\n",
    "        subset=[\n",
    "            \"Current Species\",\n",
    "            \"Next Species\",\n",
    "            \"Overlap Start\",\n",
    "            \"Overlap End\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Remove timezone information from the datetime columns in the overlaps_df\n",
    "    overlaps_df[\"Overlap Start\"] = overlaps_df[\"Overlap Start\"].dt.tz_convert(\n",
    "        None\n",
    "    )\n",
    "    overlaps_df[\"Overlap End\"] = overlaps_df[\"Overlap End\"].dt.tz_convert(None)\n",
    "\n",
    "    return overlaps_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffee4d",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd8273-7d9c-4515-9e39-1bc50be63f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata[\"filename\"] = [\n",
    "    iso_to_file_name(x) for x in original_metadata[\"End_DateTime_ISO8601\"]\n",
    "]\n",
    "original_metadata[\"begin_time\"] = [\n",
    "    get_time_in_file(x) for x in original_metadata[\"Start_DateTime_ISO8601\"]\n",
    "]\n",
    "original_metadata[\"end_time\"] = [\n",
    "    get_time_in_file(x, \"end\")\n",
    "    for x in original_metadata[\"End_DateTime_ISO8601\"]\n",
    "]\n",
    "original_metadata[\"call_length\"] = (\n",
    "    original_metadata[\"end_time\"] - original_metadata[\"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260d445-37d9-4d59-8b88-37637d1e50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split annotations that originate from different files to the corresponding files\n",
    "problematic_samples_filter = original_metadata[\"call_length\"] < 0\n",
    "after_split_samples = original_metadata[problematic_samples_filter].copy()\n",
    "original_metadata.loc[problematic_samples_filter, \"end_time\"] = FILES_DELTA\n",
    "original_metadata.loc[problematic_samples_filter, \"filename\"] = [\n",
    "    get_previous_filename(x)\n",
    "    for x in original_metadata[problematic_samples_filter][\"filename\"]\n",
    "]\n",
    "after_split_samples[\"begin_time\"] = 0\n",
    "new_metadata = pd.concat(\n",
    "    [original_metadata, after_split_samples], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586e55f-22a6-4c4f-bb28-d34c8e1fd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove calls with length of zero\n",
    "new_metadata = new_metadata[new_metadata[\"call_length\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4efcfa-19aa-4ac0-8be8-9342fdbd39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct files duration\n",
    "new_metadata = correct_call_times_with_duration(\n",
    "    new_metadata, audio_files_path=audio_files_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a0bca-b3ac-4c32-ab47-1f4eb390ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to high_prob and all data\n",
    "high_prob_metadata = new_metadata[\n",
    "    new_metadata[\"Detection_Confidence\"] == \"Detected\"\n",
    "]\n",
    "high_prob_metadata = high_prob_metadata.drop(columns=[\"Detection_Confidence\"])\n",
    "all_metadata = new_metadata.drop(columns=[\"Detection_Confidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720729c-7c8f-4f62-b61d-09f5a486dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge overlapping calls\n",
    "all_metadata = non_overlap_df(all_metadata)\n",
    "high_prob_metadata = non_overlap_df(high_prob_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata[\"unique_id\"] = (\n",
    "    all_metadata.index.astype(str)\n",
    "    + all_metadata[\"Selection\"].astype(str)\n",
    "    + all_metadata[\"filename\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3824fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps_df = calculate_overlaps_with_buffer(all_metadata, buffer_seconds=0)\n",
    "print(f\"No buffer: {overlaps_df.shape[0]} overlaps found\")\n",
    "# Example usage with different buffer durations\n",
    "buffer_1s = calculate_overlaps_with_buffer(all_metadata, buffer_seconds=1)\n",
    "print(f\"1s buffer: {buffer_1s.shape[0]} overlaps found\")\n",
    "buffer_2s = calculate_overlaps_with_buffer(all_metadata, buffer_seconds=2)\n",
    "print(f\"2s buffer: {buffer_2s.shape[0]} overlaps found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define species colors\n",
    "species_colors = {\n",
    "    \"SEWH\": \"purple\",\n",
    "    \"HUWH\": \"blue\",\n",
    "    \"FIWH\": \"orange\",\n",
    "    \"RIWH\": \"green\",\n",
    "    \"HUWH-MULTIPLE\": \"red\",\n",
    "}\n",
    "\n",
    "# species_list = df['Species'].unique()\n",
    "species_list = [\"HUWH\", \"FIWH\", \"RIWH\", \"HUWH-MULTIPLE\", \"SEWH\"]\n",
    "\n",
    "# Update the species_to_numeric mapping to include all species, including HUWH-MULTIPLE\n",
    "species_to_numeric = {\n",
    "    species: idx for idx, species in enumerate(species_colors.keys())\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot intervals\n",
    "for species in species_list:\n",
    "    species_data = all_metadata[all_metadata[\"Species\"] == species]\n",
    "    plt.barh(\n",
    "        y=species_to_numeric[species],\n",
    "        width=species_data[\"End_DateTime_ISO8601\"]\n",
    "        - species_data[\"Start_DateTime_ISO8601\"],\n",
    "        left=species_data[\"Start_DateTime_ISO8601\"],\n",
    "        height=0.3,\n",
    "        color=species_colors.get(species, \"gray\"),\n",
    "        label=species,\n",
    "    )\n",
    "\n",
    "# Plot overlaps with split colors\n",
    "for _, overlap in overlaps_df.iterrows():\n",
    "    species_1 = overlap[\"Current Species\"]\n",
    "    species_2 = overlap[\"Next Species\"]\n",
    "\n",
    "    overlap_start = overlap[\"Overlap Start\"]\n",
    "    overlap_end = overlap[\"Overlap End\"]\n",
    "    overlap_duration = overlap_end - overlap_start\n",
    "\n",
    "    # Calculate segment height (splitting into two parts)\n",
    "    segment_height = 0.3 / 2  # Splitting the height\n",
    "\n",
    "    # Plot first segment with species 1 color\n",
    "    plt.gca().add_patch(\n",
    "        patches.Rectangle(\n",
    "            (overlap_start, species_to_numeric[species_1] - segment_height),\n",
    "            overlap_duration,\n",
    "            segment_height,\n",
    "            color=species_colors[species_1],\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Plot second segment with species 2 color\n",
    "    plt.gca().add_patch(\n",
    "        patches.Rectangle(\n",
    "            (overlap_start, species_to_numeric[species_1]),\n",
    "            overlap_duration,\n",
    "            segment_height,\n",
    "            color=species_colors[species_2],\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Improve x-axis format to show only dates in vertical format\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "plt.gcf().autofmt_xdate(rotation=90)\n",
    "\n",
    "# Update y-ticks to show species names\n",
    "plt.yticks(list(species_to_numeric.values()), list(species_to_numeric.keys()))\n",
    "\n",
    "# Title and labels\n",
    "plt.title(\"Species Time Intervals with Enhanced Overlaps\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Species\")\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc60dd6-efd9-4a92-ba05-47cd5397bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all = bg_from_non_overlap_calls(all_metadata)\n",
    "with_bg_metadata_all = with_bg_metadata_all.sort_values(\n",
    "    by=[\"filename\", \"begin_time\"]\n",
    ")\n",
    "\n",
    "with_bg_metadata_high = bg_from_non_overlap_calls(high_prob_metadata)\n",
    "with_bg_metadata_high = with_bg_metadata_high.sort_values(\n",
    "    by=[\"filename\", \"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from species to unique labels\n",
    "species_to_label_all = {\n",
    "    species: idx + 1\n",
    "    for idx, species in enumerate(with_bg_metadata_all[\"Species\"].unique())\n",
    "}\n",
    "species_to_label_high = {\n",
    "    species: idx + 1\n",
    "    for idx, species in enumerate(with_bg_metadata_high[\"Species\"].unique())\n",
    "}\n",
    "\n",
    "# Assign these labels to the 'label' column where it is non-zero\n",
    "with_bg_metadata_all.loc[with_bg_metadata_all[\"label\"] != 0, \"label\"] = (\n",
    "    with_bg_metadata_all[\"Species\"].map(species_to_label_all)\n",
    ")\n",
    "with_bg_metadata_high.loc[with_bg_metadata_high[\"label\"] != 0, \"label\"] = (\n",
    "    with_bg_metadata_high[\"Species\"].map(species_to_label_high)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca64be-1f95-4090-a33a-f45c024b4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all[\"label\"] = np.array(with_bg_metadata_all[\"label\"]).astype(\n",
    "    \"int\"\n",
    ")\n",
    "with_bg_metadata_high[\"label\"] = np.array(\n",
    "    with_bg_metadata_high[\"label\"]\n",
    ").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f768b9d-aa4a-416c-b254-b272b4af41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and val\n",
    "val_filter = with_bg_metadata_all[\"filename\"].str.contains(\"20090330\")\n",
    "train_metadata = with_bg_metadata_all[~val_filter]\n",
    "val_metadata = with_bg_metadata_all[val_filter]\n",
    "print(f\"{len(train_metadata)=}, {len(val_metadata)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd294da-4c5a-4890-9648-b14187281c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for high prob\n",
    "val_filter = with_bg_metadata_high[\"filename\"].str.contains(\"20090330\")\n",
    "high_prob_train_metadata = with_bg_metadata_high[~val_filter]\n",
    "high_prob_val_metadata = with_bg_metadata_high[val_filter]\n",
    "print(f\"{len(high_prob_train_metadata)=}, {len(high_prob_val_metadata)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0e5a1-b390-41bc-9de7-b3345a75271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the bg to the high prob as well from the full dataset\n",
    "high_prob_train_metadata_calls = high_prob_train_metadata[\n",
    "    high_prob_train_metadata[\"label\"] != 0\n",
    "]\n",
    "all_bg_train = train_metadata[train_metadata[\"label\"] == 0]\n",
    "high_prob_train_metadata = pd.concat(\n",
    "    [high_prob_train_metadata_calls, all_bg_train]\n",
    ")\n",
    "high_prob_train_metadata = high_prob_train_metadata.sort_values(\n",
    "    by=[\"filename\", \"begin_time\"]\n",
    ")\n",
    "\n",
    "high_prob_val_metadata_calls = high_prob_val_metadata[\n",
    "    high_prob_val_metadata[\"label\"] != 0\n",
    "]\n",
    "all_bg_val = val_metadata[val_metadata[\"label\"] == 0]\n",
    "high_prob_val_metadata = pd.concat([high_prob_val_metadata_calls, all_bg_val])\n",
    "high_prob_val_metadata = high_prob_val_metadata.sort_values(\n",
    "    by=[\"filename\", \"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e89e0-86cc-4b40-9163-99017bef3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_in_hrs_format(time_secs):\n",
    "    return (\n",
    "        time_secs // 3600,\n",
    "        (time_secs - time_secs // 3600 * 3600) // 60,\n",
    "        time_secs % 60,\n",
    "    )\n",
    "\n",
    "\n",
    "for name, meta in {\n",
    "    \"train\": train_metadata,\n",
    "    \"val\": val_metadata,\n",
    "    \"train_high_prob\": high_prob_train_metadata,\n",
    "    \"val_high_prob\": high_prob_val_metadata,\n",
    "    \"with_bg_metadata_high\": with_bg_metadata_high,\n",
    "    \"with_bg_metadata_all\": with_bg_metadata_all,\n",
    "}.items():\n",
    "    print(name)\n",
    "    print(f\"Number of samples: {len(meta)}\")\n",
    "    print(f\"Labels breakdown: {meta['label'].value_counts()}\")\n",
    "    h, m, s = get_time_in_hrs_format(\n",
    "        meta[\"call_length\"][meta[\"label\"] == 1].sum()\n",
    "    )\n",
    "    print(f\"Calls length: {h}:{m}:{s}\")\n",
    "    h, m, s = get_time_in_hrs_format(\n",
    "        meta[\"call_length\"][meta[\"label\"] == 0].sum()\n",
    "    )\n",
    "    print(f\"Background length: {h}:{m}:{s}\")\n",
    "    # print(f\"Calls length: {time.strftime('%H:%M:%S', time.gmtime(meta['call_length'][meta['label']==1].sum()))}\")\n",
    "    # print(f\"Background length: {time.strftime('%H:%M:%S', time.gmtime(meta['call_length'][meta['label']==0].sum()))}\")\n",
    "    print(\n",
    "        \"-----------------------------------------------------------------------------\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bf6fe-ac3e-4d5c-8156-5548f2d24f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata.to_csv(\"train_all_labels.csv\", index=False)\n",
    "val_metadata.to_csv(\"val_all_labels.csv\", index=False)\n",
    "high_prob_train_metadata.to_csv(\"train_all_labels_high_prob.csv\", index=False)\n",
    "high_prob_val_metadata.to_csv(\"val_all_labels_high_prob.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundbay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
