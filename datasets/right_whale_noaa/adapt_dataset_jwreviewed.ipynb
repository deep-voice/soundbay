{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "48836b17-90bd-4aaf-a3eb-9fe74abd485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from soundbay.utils.metadata_processing import (\n",
    "    bg_from_non_overlap_calls,\n",
    "    correct_call_times_with_duration,\n",
    "    non_overlap_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c6ea5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = \"\" # Deep_Voice_NARW_Detections_JWreviewed/Selection_Tables\n",
    "audio_path = \"\" # data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f239793",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [f for f in os.listdir(annotation_path) if f.endswith('.txt')]\n",
    "original_metadata = pd.DataFrame()\n",
    "for file_path in file_paths:\n",
    "    current_df = pd.read_csv(os.path.join(annotation_path, file_path), sep='\\t')\n",
    "    current_df[\"Detection_Confidence\"] = \"\"\n",
    "    current_df.loc[current_df[\"Analyst Score\"] == \"T\", \"Detection_Confidence\"] = \"Detected\"\n",
    "    current_df['audio_path'] = audio_path\n",
    "    current_df['filename'] = file_path.split(\"/\")[-1].split(\"-\")[0]\n",
    "    original_metadata = pd.concat([original_metadata, current_df])\n",
    "\n",
    "original_metadata[\"Species\"] = \"RIWH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7ae48",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac9a25b6-83e9-41ea-b278-702b1c8fa5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_DELTA = 15 * 60  # 15 minutes files\n",
    "\n",
    "\n",
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\"\"\"\n",
    "    h, m, s = time_str.split(\":\")\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "\n",
    "def filetime_from_time(time_str):\n",
    "    sec_time = get_sec(time_str)\n",
    "    filetime_sec = math.floor(sec_time / FILES_DELTA) * FILES_DELTA\n",
    "    filetime_str = time.strftime(\"%H%M%S\", time.gmtime(filetime_sec))\n",
    "    return filetime_str\n",
    "\n",
    "\n",
    "def get_time_and_date(iso_input):\n",
    "    date, time_str = iso_input.split(\"T\")\n",
    "    time_str = time_str.split(\"-\")[0]\n",
    "    return date, time_str\n",
    "\n",
    "\n",
    "def iso_to_file_name(iso_input, format_str):\n",
    "    date, time_str = get_time_and_date(iso_input)\n",
    "    filename_time = filetime_from_time(time_str)\n",
    "    # filename_date = date.replace(\"-\", \"\")\n",
    "    return format_str.format(filename_time=filename_time)\n",
    "\n",
    "\n",
    "def get_time_in_file(iso_input, type=\"start\"):\n",
    "    date, time_str = get_time_and_date(iso_input)\n",
    "    time_int = get_sec(time_str)\n",
    "    time_in_file = time_int - (time_int // FILES_DELTA) * FILES_DELTA\n",
    "    if type == \"end\" and time_in_file == 0:\n",
    "        time_in_file = FILES_DELTA\n",
    "    return time_in_file\n",
    "\n",
    "\n",
    "def get_previous_filename(filename):\n",
    "    file_parts = filename.split(\"_\")\n",
    "    time_part = file_parts[-2]\n",
    "    h, m, s = re.findall(\"..\", time_part)\n",
    "    time_sec = int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    new_time = time_sec - FILES_DELTA\n",
    "    assert new_time % FILES_DELTA == 0, \"whyyyy\"\n",
    "    new_time_part = time.strftime(\"%H%M%S\", time.gmtime(new_time))\n",
    "    file_parts[-2] = new_time_part\n",
    "    return \"_\".join(file_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffee4d",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e394dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata.rename(columns={\"Begin Time (s)\": \"begin_time\", \"End Time (s)\": \"end_time\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4fbd8273-7d9c-4515-9e39-1bc50be63f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata[\"call_length\"] = (\n",
    "    original_metadata[\"end_time\"] - original_metadata[\"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb689828",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata = original_metadata[original_metadata.Species == \"RIWH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_metadata['Species'].value_counts())\n",
    "original_metadata['Species'] = original_metadata['Species'].apply(lambda x: 'HUWH' if 'HUWH' in x else x)\n",
    "print(original_metadata['Species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260d445-37d9-4d59-8b88-37637d1e50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove samples with negative call length\n",
    "problematic_samples_filter = original_metadata[\"call_length\"] < 0\n",
    "print(f\"Dropping {problematic_samples_filter.sum()} samples with negative call length\")\n",
    "original_metadata = original_metadata[~problematic_samples_filter]\n",
    "\n",
    "# Create new_metadata without the problematic samples\n",
    "new_metadata = original_metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e586e55f-22a6-4c4f-bb28-d34c8e1fd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove calls with length of zero\n",
    "new_metadata = new_metadata[new_metadata[\"call_length\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa4efcfa-19aa-4ac0-8be8-9342fdbd39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct files duration\n",
    "dfs = []\n",
    "for audio_path in new_metadata.audio_path.unique():\n",
    "    sub_df = new_metadata[new_metadata.audio_path == audio_path].copy()\n",
    "    sub_df = correct_call_times_with_duration(\n",
    "        sub_df, audio_files_path=audio_path\n",
    "    )\n",
    "    dfs.append(sub_df)\n",
    "new_metadata = pd.concat(dfs, ignore_index=True)\n",
    "new_metadata.drop(columns=[\"audio_path\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata[\"Detection_Confidence\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05480269",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "01ba5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by species and process each separately\n",
    "species_dfs = []\n",
    "for species in new_metadata['Species'].unique():\n",
    "    species_df = new_metadata[new_metadata['Species'] == species]\n",
    "    species_df = non_overlap_df(species_df)\n",
    "    species_dfs.append(species_df)\n",
    "\n",
    "# Combine back into single dataframe\n",
    "new_metadata = pd.concat(species_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c036cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f656a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata[\"Detection_Confidence\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c720729c-7c8f-4f62-b61d-09f5a486dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge overlapping calls\n",
    "new_metadata = non_overlap_df(new_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7338da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata[\"unique_id\"] = (\n",
    "    new_metadata.index.astype(str)\n",
    "    + new_metadata[\"Selection\"].astype(str)\n",
    "    + new_metadata[\"filename\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "afc60dd6-efd9-4a92-ba05-47cd5397bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all = bg_from_non_overlap_calls(new_metadata)\n",
    "with_bg_metadata_all = with_bg_metadata_all.sort_values(\n",
    "    by=[\"filename\", \"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73b5fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from species to unique labels\n",
    "species_to_label_all = {\n",
    "    species: idx + 1\n",
    "    for idx, species in enumerate(with_bg_metadata_all[\"Species\"].unique())\n",
    "}\n",
    "\n",
    "# Assign these labels to the 'label' column where it is non-zero\n",
    "with_bg_metadata_all.loc[(with_bg_metadata_all[\"label\"] != 0) & (with_bg_metadata_all[\"Detection_Confidence\"] == \"Detected\"), \"label\"] = (\n",
    "    with_bg_metadata_all[\"Species\"].map(species_to_label_all)\n",
    ")\n",
    "with_bg_metadata_all.loc[(with_bg_metadata_all[\"label\"] != 0) & (with_bg_metadata_all[\"Detection_Confidence\"] != \"Detected\"), \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1eca64be-1f95-4090-a33a-f45c024b4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all[\"label\"] = np.array(with_bg_metadata_all[\"label\"]).astype(\n",
    "    \"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65854864",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all[with_bg_metadata_all.label==0].call_length.value_counts()\n",
    "with_bg_metadata_all[with_bg_metadata_all.label!=0].Detection_Confidence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09ad31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_bg_metadata_all = with_bg_metadata_all[with_bg_metadata_all[\"Detection_Confidence\"] == \"Detected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all.sort_values(by=[\"filename\", \"begin_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f768b9d-aa4a-416c-b254-b272b4af41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(with_bg_metadata_all)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db528385",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_label_dict = dict(zip(with_bg_metadata_all[with_bg_metadata_all.label!=0]['Species'], with_bg_metadata_all[with_bg_metadata_all.label!=0]['label']))\n",
    "species_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420be736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_split(df, val_size=0.2, random_state=42):\n",
    "    # Get unique filenames\n",
    "    unique_files = df['filename'].unique()\n",
    "    \n",
    "    try:\n",
    "        # Try stratified split first\n",
    "        file_labels = df.groupby('filename')['label'].first()\n",
    "        train_files, val_files = train_test_split(\n",
    "            unique_files,\n",
    "            test_size=val_size,\n",
    "            random_state=random_state,\n",
    "            stratify=file_labels\n",
    "        )\n",
    "    except ValueError:\n",
    "        # Fall back to random split if stratification fails\n",
    "        print(\"Warning: Not enough samples for stratification. Performing random split instead.\")\n",
    "        train_files, val_files = train_test_split(\n",
    "            unique_files,\n",
    "            test_size=val_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    # Create train and validation masks\n",
    "    train_mask = df['filename'].isin(train_files)\n",
    "    val_mask = df['filename'].isin(val_files)\n",
    "    \n",
    "    # Split the dataframe\n",
    "    train_df = df[train_mask].copy()\n",
    "    val_df = df[val_mask].copy()\n",
    "    \n",
    "    return train_df, val_df\n",
    "\n",
    "# Apply the split\n",
    "train_data, val_data = create_train_val_split(with_bg_metadata_all)\n",
    "\n",
    "# Print split statistics\n",
    "print(f\"Training set size: {len(train_data)} ({len(train_data)/len(with_bg_metadata_all)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {len(val_data)} ({len(val_data)/len(with_bg_metadata_all)*100:.1f}%)\")\n",
    "\n",
    "# Verify label distribution\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "print(train_data['label'].value_counts(normalize=True))\n",
    "print(\"\\nLabel distribution in validation set:\")\n",
    "print(val_data['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b73bf6fe-ac3e-4d5c-8156-5548f2d24f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(f\"train_riwh_jwreviewed.csv\", index=False)\n",
    "val_data.to_csv(f\"val_riwh_jwreviewed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2141fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[with_bg_metadata_all.filename.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91f384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundbay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
