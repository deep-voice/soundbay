{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48836b17-90bd-4aaf-a3eb-9fe74abd485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from soundbay.utils.metadata_processing import (\n",
    "    bg_from_non_overlap_calls,\n",
    "    correct_call_times_with_duration,\n",
    "    non_overlap_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c6ea5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30559f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '/DeepVoice/datasets/'\n",
    "suffix = '_narw'\n",
    "\n",
    "# Get all narw dataset folders and their csv paths and wav formats\n",
    "narw_folders = [f for f in os.listdir(directory) if f.endswith(suffix)]\n",
    "csv_paths = {}\n",
    "wav_formats = {}\n",
    "\n",
    "for folder in narw_folders:\n",
    "    folder_path = os.path.join(directory, folder)\n",
    "    data_path = os.path.join(folder_path, 'data')\n",
    "    audio_path = os.path.join(folder_path, 'ancillary', 'source-audio')\n",
    "    \n",
    "    # Find the csv file in the data folder\n",
    "    if os.path.exists(data_path):\n",
    "        csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "        if csv_files:\n",
    "            csv_paths[folder] = os.path.join(data_path, csv_files[0])\n",
    "            \n",
    "    # Find wav file format in audio folder        \n",
    "    if os.path.exists(audio_path):\n",
    "        wav_files = [f for f in os.listdir(audio_path) if f.endswith('.wav')]\n",
    "        if wav_files:\n",
    "            # Get first wav file as template\n",
    "            wav_file = wav_files[0]\n",
    "            # Split on underscore and replace timestamp with format placeholder\n",
    "            parts = wav_file.split('_')\n",
    "            for i in range(len(parts)-2, -1, -1):\n",
    "                if parts[i].isdigit() and len(parts[i]) == 6:\n",
    "                    parts[i] = '{filename_time}'\n",
    "                    wav_formats[folder] = '_'.join(parts)[:-4]\n",
    "                    break\n",
    "\n",
    "print(\"CSV paths:\")                    \n",
    "print(csv_paths)\n",
    "print(\"\\nWAV formats:\")\n",
    "print(wav_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b78b9b3-727e-4ad6-9c36-c5d57050d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file into a dataframe\n",
    "# Create empty dataframe to store all metadata\n",
    "original_metadata = pd.DataFrame()\n",
    "\n",
    "# Load and concatenate all CSVs with their corresponding format string\n",
    "for folder, csv_path in csv_paths.items():\n",
    "    if wav_formats.get(folder):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['Format_String'] = wav_formats.get(folder)\n",
    "        df[\"audio_path\"] = os.path.join(directory, folder, 'ancillary', 'source-audio')\n",
    "        original_metadata = pd.concat([original_metadata, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7ae48",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9a25b6-83e9-41ea-b278-702b1c8fa5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_DELTA = 15 * 60  # 15 minutes files\n",
    "\n",
    "\n",
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\"\"\"\n",
    "    h, m, s = time_str.split(\":\")\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "\n",
    "def filetime_from_time(time_str):\n",
    "    sec_time = get_sec(time_str)\n",
    "    filetime_sec = math.floor(sec_time / FILES_DELTA) * FILES_DELTA\n",
    "    filetime_str = time.strftime(\"%H%M%S\", time.gmtime(filetime_sec))\n",
    "    return filetime_str\n",
    "\n",
    "\n",
    "def get_time_and_date(iso_input):\n",
    "    date, time_str = iso_input.split(\"T\")\n",
    "    time_str = time_str.split(\"-\")[0]\n",
    "    return date, time_str\n",
    "\n",
    "\n",
    "def iso_to_file_name(iso_input, format_str):\n",
    "    date, time_str = get_time_and_date(iso_input)\n",
    "    filename_time = filetime_from_time(time_str)\n",
    "    # filename_date = date.replace(\"-\", \"\")\n",
    "    return format_str.format(filename_time=filename_time)\n",
    "\n",
    "\n",
    "def get_time_in_file(iso_input, type=\"start\"):\n",
    "    date, time_str = get_time_and_date(iso_input)\n",
    "    time_int = get_sec(time_str)\n",
    "    time_in_file = time_int - (time_int // FILES_DELTA) * FILES_DELTA\n",
    "    if type == \"end\" and time_in_file == 0:\n",
    "        time_in_file = FILES_DELTA\n",
    "    return time_in_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffee4d",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbd8273-7d9c-4515-9e39-1bc50be63f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata[\"filename\"] = [\n",
    "    iso_to_file_name(x, original_metadata.iloc[i][\"Format_String\"]) \n",
    "    for i, x in enumerate(original_metadata[\"End_DateTime_ISO8601\"])\n",
    "]\n",
    "original_metadata[\"begin_time\"] = [\n",
    "    get_time_in_file(x) for x in original_metadata[\"Start_DateTime_ISO8601\"]\n",
    "]\n",
    "original_metadata[\"end_time\"] = [\n",
    "    get_time_in_file(x, \"end\")\n",
    "    for x in original_metadata[\"End_DateTime_ISO8601\"]\n",
    "]\n",
    "original_metadata[\"call_length\"] = (\n",
    "    original_metadata[\"end_time\"] - original_metadata[\"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5096edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_metadata = original_metadata[original_metadata.audio_path == original_metadata.audio_path.unique()[2]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647ba90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata.drop(columns=['Format_String'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d70432",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata.audio_path.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb689828",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metadata = original_metadata[original_metadata.Species == \"RIWH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed18c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_metadata = original_metadata[original_metadata.filename.str.contains('20090330')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_metadata['Species'].value_counts())\n",
    "original_metadata['Species'] = original_metadata['Species'].apply(lambda x: 'HUWH' if 'HUWH' in x else x)\n",
    "print(original_metadata['Species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260d445-37d9-4d59-8b88-37637d1e50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove samples with negative call length\n",
    "problematic_samples_filter = original_metadata[\"call_length\"] < 0\n",
    "print(f\"Dropping {problematic_samples_filter.sum()} samples with negative call length\")\n",
    "original_metadata = original_metadata[~problematic_samples_filter]\n",
    "\n",
    "# Create new_metadata without the problematic samples\n",
    "new_metadata = original_metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e586e55f-22a6-4c4f-bb28-d34c8e1fd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove calls with length of zero\n",
    "new_metadata = new_metadata[new_metadata[\"call_length\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa4efcfa-19aa-4ac0-8be8-9342fdbd39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct files duration\n",
    "dfs = []\n",
    "for audio_path in new_metadata.audio_path.unique():\n",
    "    sub_df = new_metadata[new_metadata.audio_path == audio_path].copy()\n",
    "    sub_df = correct_call_times_with_duration(\n",
    "        sub_df, audio_files_path=audio_path\n",
    "    )\n",
    "    dfs.append(sub_df)\n",
    "new_metadata = pd.concat(dfs, ignore_index=True)\n",
    "new_metadata.drop(columns=[\"audio_path\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata[\"Detection_Confidence\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05480269",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ba5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by species and process each separately\n",
    "species_dfs = []\n",
    "for species in new_metadata['Species'].unique():\n",
    "    species_df = new_metadata[new_metadata['Species'] == species]\n",
    "    species_df = non_overlap_df(species_df)\n",
    "    species_dfs.append(species_df)\n",
    "\n",
    "# Combine back into single dataframe\n",
    "new_metadata = pd.concat(species_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c036cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f656a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata[\"Detection_Confidence\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c720729c-7c8f-4f62-b61d-09f5a486dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge overlapping calls\n",
    "new_metadata = non_overlap_df(new_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7338da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata[\"unique_id\"] = (\n",
    "    new_metadata.index.astype(str)\n",
    "    + new_metadata[\"Selection\"].astype(str)\n",
    "    + new_metadata[\"filename\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afc60dd6-efd9-4a92-ba05-47cd5397bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all = bg_from_non_overlap_calls(new_metadata)\n",
    "with_bg_metadata_all = with_bg_metadata_all.sort_values(\n",
    "    by=[\"filename\", \"begin_time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b5fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from species to unique labels\n",
    "species_to_label_all = {\n",
    "    species: idx + 1\n",
    "    for idx, species in enumerate(with_bg_metadata_all[\"Species\"].unique())\n",
    "}\n",
    "\n",
    "# Assign these labels to the 'label' column where it is non-zero\n",
    "with_bg_metadata_all.loc[(with_bg_metadata_all[\"label\"] != 0) & (with_bg_metadata_all[\"Detection_Confidence\"] == \"Detected\"), \"label\"] = (\n",
    "    with_bg_metadata_all[\"Species\"].map(species_to_label_all)\n",
    ")\n",
    "with_bg_metadata_all.loc[(with_bg_metadata_all[\"label\"] != 0) & (with_bg_metadata_all[\"Detection_Confidence\"] != \"Detected\"), \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eca64be-1f95-4090-a33a-f45c024b4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all[\"label\"] = np.array(with_bg_metadata_all[\"label\"]).astype(\n",
    "    \"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_bg_metadata_all.sort_values(by=[\"filename\", \"begin_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ad31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_bg_metadata_all = with_bg_metadata_all[with_bg_metadata_all[\"Detection_Confidence\"] == \"Detected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f768b9d-aa4a-416c-b254-b272b4af41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(with_bg_metadata_all)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db528385",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_label_dict = dict(zip(with_bg_metadata_all[with_bg_metadata_all.label!=0]['Species'], with_bg_metadata_all[with_bg_metadata_all.label!=0]['label']))\n",
    "species_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming with_bg_metadata_all is your DataFrame\n",
    "# Group by filename and stratify by label\n",
    "\n",
    "def create_train_val_split(df, val_size=0.2, random_state=42):\n",
    "    # Get unique filenames\n",
    "    unique_files = df['filename'].unique()\n",
    "    \n",
    "    # Get one label per file (assuming same file has same label)\n",
    "    file_labels = df.groupby('filename')['label'].first()\n",
    "    \n",
    "    # Split filenames while stratifying by their labels\n",
    "    train_files, val_files = train_test_split(\n",
    "        unique_files,\n",
    "        test_size=val_size,\n",
    "        random_state=random_state,\n",
    "        stratify=file_labels\n",
    "    )\n",
    "    \n",
    "    # Create train and validation masks\n",
    "    train_mask = df['filename'].isin(train_files)\n",
    "    val_mask = df['filename'].isin(val_files)\n",
    "    \n",
    "    # Split the dataframe\n",
    "    train_df = df[train_mask].copy()\n",
    "    val_df = df[val_mask].copy()\n",
    "    \n",
    "    return train_df, val_df\n",
    "\n",
    "# Apply the split\n",
    "train_data, val_data = create_train_val_split(with_bg_metadata_all)\n",
    "\n",
    "# Print split statistics\n",
    "print(f\"Training set size: {len(train_data)} ({len(train_data)/len(with_bg_metadata_all)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {len(val_data)} ({len(val_data)/len(with_bg_metadata_all)*100:.1f}%)\")\n",
    "\n",
    "# Verify label distribution\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "print(train_data['label'].value_counts(normalize=True))\n",
    "print(\"\\nLabel distribution in validation set:\")\n",
    "print(val_data['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b73bf6fe-ac3e-4d5c-8156-5548f2d24f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(f\"train_riwh_narw.csv\", index=False)\n",
    "val_data.to_csv(f\"val_riwh_narw.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91f384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundbay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
