{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from tqdm import tqdm\n",
    "from soundbay.utils.metadata_processing import bg_from_non_overlap_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gzip_files(input_dir):\n",
    "    # find all .txt files in the dir\n",
    "    all_files = os.listdir(input_dir)\n",
    "    txt_files = [f for f in all_files if f.endswith('.txt')]\n",
    "    print(f'Found {len(txt_files)} txt files')\n",
    "    for txt_file in txt_files:\n",
    "        txt_file_path = os.path.join(input_dir, txt_file)\n",
    "        print(f'Processing {txt_file_path}')\n",
    "        # Rename the txt to include .gz at the end. For example mv tomer.txt tomer.txt.gz\n",
    "        # unzip using gzip: gzip -d tomer.txt.gz\n",
    "        os.system(f'mv \"{txt_file_path}\" \"{txt_file_path}.gz\"')\n",
    "        os.system(f'gzip -d \"{txt_file_path}.gz\"')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '~/Downloads/FlumeL_m_23.04.11.Sounds.selections_DV (1).txt'\n",
    "def get_files(main_dir):\n",
    "\n",
    "    files = []\n",
    "    for r, d, f in os.walk(main_dir):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(r, file))\n",
    "    files = [f for f in files if f.endswith('.txt')]\n",
    "    all_dfs = {}\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        # leave filename basename\n",
    "        file = os.path.basename(file)\n",
    "        all_dfs[file] = df\n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "# main_dir = '/Users/tomernahshon/Documents/soundbay/shaye_data/all_txt_9.3.24_concluded'\n",
    "main_dir = '/datadrive/soundbay_backup/txt_files_19.10.24/'\n",
    "# process_gzip_files(main_dir)\n",
    "all_dfs = get_files(main_dir)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = get_files(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (filename, df) in enumerate(all_dfs.items()):\n",
    "    # strip filename to file name only\n",
    "    # filename = filename.split('/')[-1]\n",
    "    if 'sounds' in filename.lower():\n",
    "        print(f'file: {filename} , shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    # df_copy = df.copy()\n",
    "    # df['s3_filepath'] = file_path\n",
    "    df['filename'] = df['Begin File'][:-4]\n",
    "    df['call_length'] = df['End Time (s)'] - df['Begin Time (s)']\n",
    "    df['begin_time'] = df['File Offset (s)']\n",
    "    df['end_time'] = df['begin_time'] + df['call_length']\n",
    "    df['label'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dfs['FlumeL_m_23.04.11.Sounds.selections_DV.txt'].head()\n",
    "\n",
    "# processed_df = process_df(all_dfs['FlumeL_m_23.04.11.Sounds.selections_DV.txt'])\n",
    "\n",
    "# remove all columns that are not part of process_df function\n",
    "# columns_to_keep = ['filename', 'call_length', 'begin_time', 'end_time', 'label']\n",
    "# remove all other columns\n",
    "# processed_df = processed_df[columns_to_keep]\n",
    "\n",
    "\n",
    "# Begin File - file name\n",
    "# Begin path - file path (change to s3 folder bucket)\n",
    "# call_length - all_dfs['End Time (s)'] - all_dfs['FlumeL_m_23.04.11.Sounds.selections_DV.txt']['Begin Time (s)']\n",
    "# label\n",
    "# filename\n",
    "# begin_time - File Offset (s)\n",
    "# end_time - begin_time + call_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folders(s3_path, my_bucket='deepvoice-user-uploads'):\n",
    "    import boto3\n",
    "    list_of_folders = []\n",
    "    client = boto3.client('s3')\n",
    "    result = client.list_objects(Bucket=my_bucket, Prefix=s3_path, Delimiter='/')\n",
    "    for o in result.get('CommonPrefixes'):\n",
    "            fold = o.get('Prefix').strip(s3_path)\n",
    "            if 'wav' in fold:\n",
    "                    list_of_folders.append(fold)\n",
    "\n",
    "\n",
    "    return list_of_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(s3_path, filename, s3, folders_list, my_bucket='deepvoice-user-uploads'):\n",
    "    # folders_list = ['FlumeL_m_23.03.26-23.04.11_wav shaye tudor'\n",
    "    #             ,'FlumeL_m_23.04.11-23.04.23_wav shaye tudor'\n",
    "    #             ,'FlumeL_m_23.04.24-23.05.09_wav shaye tudor'\n",
    "    #             ,'LOOT_03.10.23_wav shaye tudor'\n",
    "    #             ,'LOOT_23.03.10-23.03.28_wav shaye tudor'\n",
    "    #             ,'LOOT_23.03.29-23.04.12_wav shaye tudor']\n",
    "    for folder in folders_list:\n",
    "\n",
    "        try:\n",
    "            path = os.path.join(s3_path , folder , filename)\n",
    "            # print(path)\n",
    "            s3.head_object(Bucket=my_bucket, Key=path)\n",
    "            # print(f\"The file {filename} exists in the S3 path.\")\n",
    "            return 's3://' + my_bucket + '/' + s3_path + folder\n",
    "        except:\n",
    "            # print(f\"The file {filename} does not exist in the S3 path.\")\n",
    "            pass\n",
    "        \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_parent_folder = 'shayetudor@gmail.com/dropbox/cods/'\n",
    "list_of_folders = [i[:-1] + ' tudor' for i in get_folders(s3_parent_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['filename', 'call_length', 'begin_time', 'end_time', 'label']\n",
    "import boto3\n",
    "AWS_ACCESS_KEY = ''\n",
    "AWS_SECRET_KEY = ''\n",
    "# s3://deepvoice-user-uploads\n",
    "s3_parent_folder = 'shayetudor@gmail.com/dropbox/cods/'\n",
    "\n",
    "# filename = '7205.230413160010.wav'\n",
    "# Check if filename exists in s3_path using boto3 head function\n",
    "# s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "\n",
    "\n",
    "all_edited_dfs = []\n",
    "for j, (annotations_filename, df) in enumerate(tqdm(all_dfs.items())):\n",
    "\n",
    "    if 'sounds' in annotations_filename.lower():\n",
    "        processed_df = process_df(df)\n",
    "\n",
    "        # remove all other columns\n",
    "        processed_df = processed_df[columns_to_keep]\n",
    "        processed_df['annotations_filename'] = annotations_filename\n",
    "        for i, row in processed_df.iterrows():\n",
    "            if type(row['filename']) != str:\n",
    "                continue\n",
    "            filename = row['filename']\n",
    "            s3_specific_path = check_file_exists(s3_parent_folder, filename, s3, list_of_folders)\n",
    "            if s3_specific_path:\n",
    "                processed_df.loc[i, 's3_path'] = s3_specific_path\n",
    "            else:\n",
    "                processed_df.loc[i, 's3_path'] = 'None'\n",
    "        all_edited_dfs.append(processed_df)\n",
    "\n",
    "\n",
    "all_edited_dfs = pd.concat(all_edited_dfs)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs['annotations_filename'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs = all_edited_dfs[all_edited_dfs['annotations_filename'] != 'FlumeL_m_sample.quiet_Sounds.selections.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs = all_edited_dfs[(all_edited_dfs['s3_path'] != 'None')].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edited_dfs['call_length'].round(2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove heavy outliers\n",
    "all_edited_dfs = all_edited_dfs[all_edited_dfs['call_length'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = all_edited_dfs.sort_values('begin_time', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = bg_from_non_overlap_calls(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf[newdf['label'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = newdf.iloc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['s3_path'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['col_3'] = df.apply(lambda x: f(x.col_1, x.col_2), axis=1)\n",
    "\n",
    "newdf['filename'] = newdf['filename'].apply(lambda x: str(x[:-4]))\n",
    "# newdf['s3_path'] = newdf['s3_path'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['s3_path'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['s3_path'] = newdf['s3_path'] + '/' + newdf['filename'] + '.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['s3_path'].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv('/datadrive/soundbay_backup/soundbay/shaye_annotations_22_10_24.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pywhale",
   "language": "python",
   "name": "pywhale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
